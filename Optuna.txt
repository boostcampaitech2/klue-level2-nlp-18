def train() : 

    def model_init():  ###train í•¨ìˆ˜ ì•ˆì— ë„£ì–´ì£¼ì–´ì—¬ í•©ë‹ˆë‹¤
        return model

    trainer = Trainer(    
        model_init = model_init,       #ê¸°ì¡´ì— modeldì„ model_initìœ¼ë¡œ ë°”ê¾¸ì–´ì•¼í•©ë‹ˆë‹¤  # the instantiated ğŸ¤— Transformers model to be trained
        args=training_args,                  # training arguments, defined above
        train_dataset=RE_train_dataset,         # training dataset
        eval_dataset=RE_train_dataset,             # evaluation dataset
        compute_metrics=compute_metrics  # define metrics function
            
)
    ###Optuna í™˜ê²½ì„¤ì • : íŒŒë¼ë¯¸í„° ê°’ì˜ ë²”ìœ„ë¥¼ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
    def optuna_hp_space(trial):
        return {
        "random_state": trial.suggest_float('random_state', 18 , 42),
        "save_steps" : 500,          # model saving step.
        "num_train_epochs" : trial.suggest_int('num_train_epochs', 3, 6),         # total number of training epochs
        "learning_rate" : trial.suggest_float('learning_rate', 5e-5, 5e-4),               # learning_rate
        "per_device_train_batch_size" : trial.suggest_int('train_batch_size', 16, 64),  # batch size per device during training
        "per_device_eval_batch_size" : trial.suggest_int('dev_batch_size', 16, 64) ,   # batch size for evaluation
        "warmup_steps" : trial.suggest_int('warmup_steps', 100, 1000),                # number of warmup steps for learning rate scheduler
        "weight_decay" : trial.suggest_int('weight_decay', 0.005, 0.05),               # strength of weight decay
            # directory for storing logs
        # log saving step.
        
        }
    ##Hugging faceì—ì„œëŠ” hyperparameter_search ëª¨ë“ˆì„ í†µí•´ì„œ ì´ë¥¼ ì§€ì›í•´ì¤ë‹ˆë‹¤. n_trialì€ ì „ì²´ epochë¥¼ ëŒë¦°
    # íƒìƒ‰ì„ í†µí•´ ìµœì ê°’ì„ ì°¾ì•„ë‚´ë©´ ì´ë¥¼ ê°€ì§€ê³  ë‹¤ì‹œ í•œë²ˆ í•™ìŠµí•©ë‹ˆë‹¤.
    trainer.hyperparameter_search(
        direction="maximize", # NOTE: or direction="minimize"
        hp_space=optuna_hp_space, # NOTE: if you wanna use optuna, change it to optuna_hp_space
        n_trials = 2,
        #backend="ray", # NOTE: if you wanna use optuna, remove this argument
    )

    trianer.train()


